---
title: "Databrary Volume Survey"
subtitle: "Version 2.0"
author: "Rick Gilmore"
date: "`r Sys.time()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

This document provides preliminary results from a survey of all Databrary volumes conducted in October and November 2021 by members of the Gilmore lab team.

# Report strategy

1. Import data from the shared Google sheet.
2. Clean the data.
3. Summarize and visualize the data.

# Import

Data are stored in a shared Google sheet located at the following URL:

<https://docs.google.com/spreadsheets/d/1WXY82Xi4AGbNkClkqnUxCnxcrdnwLKU6Ki-9L9e3TbU/edit#gid=0>

ROG has restricted access to this sheet since we finished the initial coding.

We'll use the `googlesheets4` package in the `googledrive` package.

Check to see if package is installed, and if not, install it and the related `tidyverse` package we'll need later.

```{r}
if(!require(googledrive)) {
  install.packages('googledrive')
}

if(!require(tidyverse)) {
  install.packages('tidyverse')
}

# Bring tidyverse into local workspace for pipe '%>%' operator
library(tidyverse)
```

Since we  know the Google-unique identifier, we can access it directly (and more quickly).

```{r}
vols_sheet_id <- '1WXY82Xi4AGbNkClkqnUxCnxcrdnwLKU6Ki-9L9e3TbU'
vols_data_drib_2 <- googledrive::drive_get(id = vols_sheet_id)
```

Now we can download the file.

```{r}
googledrive::drive_download(file = 'databrary-volume-survey', path = 'csv/databrary-volume-survey', type = 'csv', overwrite = TRUE)
```

Next, we can import it into R.

```{r}
vols_df <- readr::read_csv('csv/databrary-volume-survey.csv')
str(vols_df)
```

# Visualize

Let's summarize `sharing_level` by `coder` as a warm-up. We save the output so that we can use the data in the next step. There is another way to do this, but this seems to work.

```{r}
vols_tab <- xtabs(~ coder + sharing_level, data = vols_df)
vols_tab
```

Next, let's see who did a lot of coding.

```{r}
vols_tab_df <- as.data.frame(vols_tab)

vols_tab_summ_df <- vols_tab_df %>%
  dplyr::group_by(., coder) %>%
  dplyr::summarize(., tot_vols = sum(Freq))

vols_tab_summ_df %>%
  dplyr::group_by(., coder) %>%
  dplyr::arrange(., desc(tot_vols))
```
Go, Maggie, Andrea, Kavya, Andrea, Belle, Shahir, Bowen, and Kayla!

## How much data is shared vs. not-shared?

As a first pass, let's look at the number of files stored (`n_files`) by `sharing_level`.

```{r}
vols_df %>%
  dplyr::select(., sharing_level, n_files) %>%
  dplyr::mutate(., n_files = as.numeric(n_files)) %>%
  dplyr::filter(., sharing_level != '404 Not Found',
                n_files != is.na(n_files)) %>%
  dplyr::group_by(., sharing_level) %>%
  dplyr::summarize(., tot_files = sum(n_files))
```

## Which investigators use Databrary a lot?

To answer this question, we have to generate a new, augmented data file that includes all of the investigators associated with each volume.

The `databraryapi::list_volume_owners(vol_id)` function provides a data frame with this information.

Rick Gilmore used this commmand to generate a data file of volume owners that is saved in `csv/databrary-shared-volume-owners.csv`. Let's download the Google sheet with the private volume owners' data.

```{r}
googledrive::drive_download(file = 'databrary-owners', path = 'csv/databrary-private-volume-owners', type = 'csv', overwrite = TRUE)
```

We should now be able to merge the owner files.

```{r}
shared_vols_owns <- readr::read_csv("csv/databrary-shared-volume-owners.csv")

shared_vols_owns <- shared_vols_owns %>%
  dplyr::mutate(., sortname = tolower(sortname)) %>%
  dplyr::select(., vol_id, person_id, sortname)

private_vols_owns <- readr::read_csv("csv/databrary-private-volume-owners.csv")
private_vols_owns <- private_vols_owns %>%
  dplyr::mutate(., sortname = tolower(sortname)) %>%
  dplyr::select(., vol_id, person_id, sortname)

all_vols_owns <- rbind(shared_vols_owns, private_vols_owns)

all_vols_owns <- all_vols_owns %>%
  dplyr::arrange(., vol_id, person_id) %>%
  dplyr::rename(., volume_id = vol_id,
                investigator_last = sortname)
```

And then we can merge this data with the volumes data.

```{r}
merged_volumes_df <- dplyr::left_join(vols_df, all_vols_owns, by = 'volume_id')

str(merged_volumes_df)
```

So, now we can see which investigators use Databrary to store large numbers of files.

Let's look at the number of volumes/investigator. But first, we exclude those volumes that appear to be deleted.

```{r}
complete_volumes <- merged_volumes_df %>%
  dplyr::filter(., sharing_level != '404 Not Found')
```

So, now we can ask which investigator(s) have the largest number of volumes.

### All volumes

```{r}
complete_volumes %>%
  dplyr::select(., volume_id, person_id, investigator_last) %>%
  dplyr::group_by(., person_id, investigator_last) %>%
  dplyr::summarise(., n_vols = n()) %>%
  dplyr::arrange(., desc(n_vols))
```

### Private volumes

Let's see what's going on by limiting the summary to volumes that are private.

```{r}
complete_volumes %>%
  dplyr::select(., volume_id, person_id, investigator_last, sharing_level) %>%
  dplyr::filter(., sharing_level == 'private') %>%
  dplyr::group_by(., person_id, investigator_last) %>%
  dplyr::summarise(., n_vols = n()) %>%
  dplyr::arrange(., desc(n_vols))
```

### Overview volumes

```{r}
complete_volumes %>%
  dplyr::select(., volume_id, person_id, investigator_last, sharing_level) %>%
  dplyr::filter(., sharing_level == 'overview') %>%
  dplyr::group_by(., person_id, investigator_last) %>%
  dplyr::summarise(., n_vols = n()) %>%
  dplyr::arrange(., desc(n_vols))
```
### Entire volumes

```{r}
complete_volumes %>%
  dplyr::select(., volume_id, person_id, investigator_last, sharing_level) %>%
  dplyr::filter(., sharing_level == 'entire') %>%
  dplyr::group_by(., person_id, investigator_last) %>%
  dplyr::summarise(., n_vols = n()) %>%
  dplyr::arrange(., desc(n_vols))
```

# Clean up

```{r}
databraryapi::logout_db()
```

